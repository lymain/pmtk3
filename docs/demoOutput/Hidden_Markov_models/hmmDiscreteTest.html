
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><title>Simple test of hmmDiscreteFitEm</title><meta name="generator" content="MATLAB 7.10"><meta name="date" content="2010-05-24"><meta name="m-file" content="hmmDiscreteTest"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Simple test of hmmDiscreteFitEm</h1><!--introduction--><p>We compare how well the true model can decode a sequence, compared to a model learned via EM using the best permutation of the labels.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#2">Define the generating model</a></li><li><a href="#3">Sample</a></li><li><a href="#4">Learn the model using EM with random restarts</a></li><li><a href="#5">How different are the respective log probabilities?</a></li><li><a href="#6">Decode using true model</a></li><li><a href="#7">Decode using the EM model</a></li></ul></div><h2>Define the generating model<a name="2"></a></h2><pre class="codeinput">setSeed(0);
nHidStates = 4;
trueModel.emission = [1/6  1/6   1/6   1/6   1/6   1/6  ;
                     1/10  1/10  1/10  1/10  1/10  5/10
                     2/6   1/6   1/6   16    1/12  1/12
                     7/12   1/12  1/12  1/12  1/12 1/12];

trueModel.A = [0.6 0.15 0.20 0.05;
              0.10 0.70 0.15 0.05
              0.10 0.30 0.10 0.50
              0.30 0.10 0.30 0.30];

trueModel.pi = [0.8 0.1 0.1 0];
trueModel.type = <span class="string">'discrete'</span>;
</pre><h2>Sample<a name="3"></a></h2><pre class="codeinput">len = 100;
[observed, hidden] = hmmSample(trueModel, len);
hidden = hidden{1};
</pre><h2>Learn the model using EM with random restarts<a name="4"></a></h2><pre class="codeinput">nrestarts = 2;
modelEM = hmmFitEm(observed, nHidStates, <span class="string">'discrete'</span>, <span class="keyword">...</span>
    <span class="string">'convTol'</span>, 1e-5, <span class="string">'nRandomRestarts'</span>, nrestarts, <span class="string">'verbose'</span>, true);
</pre><pre class="codeoutput">
********** Random Restart 1 **********
1	 loglik: -259.264
2	 loglik: -241.957
3	 loglik: -240.977
4	 loglik: -240.49
5	 loglik: -240.221
6	 loglik: -240.06
7	 loglik: -239.958
8	 loglik: -239.89
9	 loglik: -239.842
10	 loglik: -239.806
11	 loglik: -239.779
12	 loglik: -239.756
13	 loglik: -239.738
14	 loglik: -239.722
15	 loglik: -239.709
16	 loglik: -239.697
17	 loglik: -239.687
18	 loglik: -239.679
19	 loglik: -239.671
20	 loglik: -239.664
21	 loglik: -239.658
22	 loglik: -239.653
23	 loglik: -239.649
24	 loglik: -239.645
25	 loglik: -239.642
26	 loglik: -239.639
27	 loglik: -239.636
28	 loglik: -239.634

********** Random Restart 2 **********
1	 loglik: -262.244
2	 loglik: -241.936
3	 loglik: -240.926
4	 loglik: -240.445
5	 loglik: -240.182
6	 loglik: -240.027
7	 loglik: -239.932
8	 loglik: -239.87
9	 loglik: -239.827
10	 loglik: -239.797
11	 loglik: -239.773
12	 loglik: -239.755
13	 loglik: -239.74
14	 loglik: -239.728
15	 loglik: -239.717
16	 loglik: -239.707
17	 loglik: -239.698
18	 loglik: -239.69
19	 loglik: -239.683
20	 loglik: -239.676
21	 loglik: -239.67
22	 loglik: -239.665
23	 loglik: -239.66
24	 loglik: -239.655
25	 loglik: -239.651
26	 loglik: -239.647
27	 loglik: -239.644
28	 loglik: -239.641
29	 loglik: -239.639
30	 loglik: -239.636
</pre><h2>How different are the respective log probabilities?<a name="5"></a></h2><pre class="codeinput">fprintf(<span class="string">'trueModel LL: %g\n'</span>, hmmLogprob(trueModel, observed));
fprintf(<span class="string">'emModel LL: %g\n'</span>, hmmLogprob(modelEM, observed));
</pre><pre class="codeoutput">trueModel LL: -136.847
emModel LL: -167.03
</pre><h2>Decode using true model<a name="6"></a></h2><pre class="codeinput">decodedFromTrueViterbi = hmmEstState(trueModel, observed);
decodedFromTrueViterbi = bestPermutation(decodedFromTrueViterbi, hidden);
trueModelViterbiError = mean(decodedFromTrueViterbi ~= hidden)

decodedFromTrueMaxMarg = maxidx(hmmInferState(trueModel, observed), [], 1);
decodedFromTrueMaxMarg = bestPermutation(decodedFromTrueMaxMarg, hidden);
trueModelMaxMargError = mean(decodedFromTrueMaxMarg ~= hidden)
</pre><pre class="codeoutput">trueModelViterbiError =
    0.4400
trueModelMaxMargError =
    0.4200
</pre><h2>Decode using the EM model<a name="7"></a></h2><pre class="codeinput">decodedFromEMviterbi = hmmEstState(modelEM, observed);
decodedFromEMviterbi = bestPermutation(decodedFromEMviterbi, hidden);

emModelViterbiError = mean(decodedFromEMviterbi ~= hidden)

decodedFromEMmaxMarg = maxidx(hmmInferState(modelEM, observed), [], 1);
decodedFromEMmaxMarg = bestPermutation(decodedFromEMmaxMarg, hidden);

emModelMaxMargError = mean(decodedFromEMmaxMarg ~= hidden)
</pre><pre class="codeoutput">emModelViterbiError =
    0.5100
emModelMaxMargError =
    0.5200
</pre><p class="footer"><br>
      Published with MATLAB&reg; 7.10<br></p></div><!--
##### SOURCE BEGIN #####
%% Simple test of hmmDiscreteFitEm
% We compare how well the true model can decode a sequence, compared to a
% model learned via EM using the best permutation of the labels. 
%%
%% Define the generating model
setSeed(0);
nHidStates = 4; 
trueModel.emission = [1/6  1/6   1/6   1/6   1/6   1/6  ;  
                     1/10  1/10  1/10  1/10  1/10  5/10 
                     2/6   1/6   1/6   16    1/12  1/12
                     7/12   1/12  1/12  1/12  1/12 1/12];  
    
trueModel.A = [0.6 0.15 0.20 0.05;
              0.10 0.70 0.15 0.05
              0.10 0.30 0.10 0.50
              0.30 0.10 0.30 0.30];

trueModel.pi = [0.8 0.1 0.1 0];
trueModel.type = 'discrete';
%% Sample
len = 100;
[observed, hidden] = hmmSample(trueModel, len);
hidden = hidden{1};
%% Learn the model using EM with random restarts
nrestarts = 2;
modelEM = hmmFitEm(observed, nHidStates, 'discrete', ...
    'convTol', 1e-5, 'nRandomRestarts', nrestarts, 'verbose', true);

%% How different are the respective log probabilities?
fprintf('trueModel LL: %g\n', hmmLogprob(trueModel, observed));
fprintf('emModel LL: %g\n', hmmLogprob(modelEM, observed)); 

%% Decode using true model
decodedFromTrueViterbi = hmmEstState(trueModel, observed);
decodedFromTrueViterbi = bestPermutation(decodedFromTrueViterbi, hidden);
trueModelViterbiError = mean(decodedFromTrueViterbi ~= hidden)

decodedFromTrueMaxMarg = maxidx(hmmInferState(trueModel, observed), [], 1);
decodedFromTrueMaxMarg = bestPermutation(decodedFromTrueMaxMarg, hidden);
trueModelMaxMargError = mean(decodedFromTrueMaxMarg ~= hidden)

%% Decode using the EM model
decodedFromEMviterbi = hmmEstState(modelEM, observed);
decodedFromEMviterbi = bestPermutation(decodedFromEMviterbi, hidden);

emModelViterbiError = mean(decodedFromEMviterbi ~= hidden)

decodedFromEMmaxMarg = maxidx(hmmInferState(modelEM, observed), [], 1);
decodedFromEMmaxMarg = bestPermutation(decodedFromEMmaxMarg, hidden);

emModelMaxMargError = mean(decodedFromEMmaxMarg ~= hidden)




##### SOURCE END #####
--></body></html>

<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><title>Simple test of hmmDiscreteFitEm</title><meta name="generator" content="MATLAB 7.10"><meta name="date" content="2010-07-27"><meta name="m-file" content="hmmDiscreteTest"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Simple test of hmmDiscreteFitEm</h1><!--introduction--><p>We compare how well the true model can decode a sequence, compared to a model learned via EM using the best permutation of the labels.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#2">Define the generating model</a></li><li><a href="#3">Sample</a></li><li><a href="#4">Learn the model using EM with random restarts</a></li><li><a href="#5">How different are the respective log probabilities?</a></li><li><a href="#6">Decode using true model</a></li><li><a href="#7">Decode using the EM model</a></li></ul></div><h2>Define the generating model<a name="2"></a></h2><pre class="codeinput">setSeed(0);
nHidStates = 4;
T =                  [1/6  1/6   1/6   1/6   1/6   1/6  ;
                     1/10  1/10  1/10  1/10  1/10  5/10
                     2/6   1/6   1/6   16    1/12  1/12
                     7/12   1/12  1/12  1/12  1/12 1/12];
trueModel.emission = tabularCpdCreate(T);

trueModel.A = [0.6 0.15 0.20 0.05;
              0.10 0.70 0.15 0.05
              0.10 0.30 0.10 0.50
              0.30 0.10 0.30 0.30];

trueModel.pi = [0.8 0.1 0.1 0];
trueModel.type = <span class="string">'discrete'</span>;
</pre><h2>Sample<a name="3"></a></h2><pre class="codeinput">len = 100;
[observed, hidden] = hmmSample(trueModel, len);
</pre><h2>Learn the model using EM with random restarts<a name="4"></a></h2><pre class="codeinput">nrestarts = 2;
modelEM = hmmFit(observed, nHidStates, <span class="string">'discrete'</span>, <span class="keyword">...</span>
    <span class="string">'convTol'</span>, 1e-5, <span class="string">'nRandomRestarts'</span>, nrestarts, <span class="string">'verbose'</span>, true);
</pre><pre class="codeoutput">
********** Random Restart 1 **********
1	 loglik: -249.457
2	 loglik: -244.708
3	 loglik: -243.094
4	 loglik: -242.126
5	 loglik: -241.486
6	 loglik: -241.045
7	 loglik: -240.735
8	 loglik: -240.515
9	 loglik: -240.356
10	 loglik: -240.241
11	 loglik: -240.157
12	 loglik: -240.095
13	 loglik: -240.048
14	 loglik: -240.012
15	 loglik: -239.985
16	 loglik: -239.963
17	 loglik: -239.946
18	 loglik: -239.933
19	 loglik: -239.922
20	 loglik: -239.913
21	 loglik: -239.905
22	 loglik: -239.899
23	 loglik: -239.894
24	 loglik: -239.89
25	 loglik: -239.886
26	 loglik: -239.883
27	 loglik: -239.88
28	 loglik: -239.877
29	 loglik: -239.875

********** Random Restart 2 **********
1	 loglik: -256.121
2	 loglik: -242.696
3	 loglik: -241.372
4	 loglik: -240.719
5	 loglik: -240.358
6	 loglik: -240.144
7	 loglik: -240.011
8	 loglik: -239.924
9	 loglik: -239.864
10	 loglik: -239.821
11	 loglik: -239.789
12	 loglik: -239.764
13	 loglik: -239.744
14	 loglik: -239.728
15	 loglik: -239.714
16	 loglik: -239.702
17	 loglik: -239.692
18	 loglik: -239.684
19	 loglik: -239.676
20	 loglik: -239.669
21	 loglik: -239.663
22	 loglik: -239.658
23	 loglik: -239.653
24	 loglik: -239.649
25	 loglik: -239.646
26	 loglik: -239.642
27	 loglik: -239.639
28	 loglik: -239.637
29	 loglik: -239.635
</pre><h2>How different are the respective log probabilities?<a name="5"></a></h2><pre class="codeinput">fprintf(<span class="string">'trueModel LL: %g\n'</span>, hmmLogprob(trueModel, observed));
fprintf(<span class="string">'emModel LL: %g\n'</span>, hmmLogprob(modelEM, observed));
</pre><pre class="codeoutput">trueModel LL: -136.847
emModel LL: -167.03
</pre><h2>Decode using true model<a name="6"></a></h2><pre class="codeinput">decodedFromTrueViterbi = hmmMap(trueModel, observed);
decodedFromTrueViterbi = bestPermutation(decodedFromTrueViterbi, hidden);
trueModelViterbiError = mean(decodedFromTrueViterbi ~= hidden)

decodedFromTrueMaxMarg = maxidx(hmmInferNodes(trueModel, observed), [], 1);
decodedFromTrueMaxMarg = bestPermutation(decodedFromTrueMaxMarg, hidden);
trueModelMaxMargError = mean(decodedFromTrueMaxMarg ~= hidden)
</pre><pre class="codeoutput">trueModelViterbiError =
   0.440000000000000
trueModelMaxMargError =
   0.420000000000000
</pre><h2>Decode using the EM model<a name="7"></a></h2><pre class="codeinput">decodedFromEMviterbi = hmmMap(modelEM, observed);
decodedFromEMviterbi = bestPermutation(decodedFromEMviterbi, hidden);

emModelViterbiError = mean(decodedFromEMviterbi ~= hidden)

decodedFromEMmaxMarg = maxidx(hmmInferNodes(modelEM, observed), [], 1);
decodedFromEMmaxMarg = bestPermutation(decodedFromEMmaxMarg, hidden);

emModelMaxMargError = mean(decodedFromEMmaxMarg ~= hidden)
</pre><pre class="codeoutput">emModelViterbiError =
   0.480000000000000
emModelMaxMargError =
   0.480000000000000
</pre><p class="footer"><br>
      Published with MATLAB&reg; 7.10<br></p></div><!--
##### SOURCE BEGIN #####
%% Simple test of hmmDiscreteFitEm
% We compare how well the true model can decode a sequence, compared to a
% model learned via EM using the best permutation of the labels. 
%%
%% Define the generating model
setSeed(0);
nHidStates = 4; 
T =                  [1/6  1/6   1/6   1/6   1/6   1/6  ;  
                     1/10  1/10  1/10  1/10  1/10  5/10 
                     2/6   1/6   1/6   16    1/12  1/12
                     7/12   1/12  1/12  1/12  1/12 1/12];  
trueModel.emission = tabularCpdCreate(T);                  
    
trueModel.A = [0.6 0.15 0.20 0.05;
              0.10 0.70 0.15 0.05
              0.10 0.30 0.10 0.50
              0.30 0.10 0.30 0.30];

trueModel.pi = [0.8 0.1 0.1 0];
trueModel.type = 'discrete';
%% Sample
len = 100;
[observed, hidden] = hmmSample(trueModel, len);

%% Learn the model using EM with random restarts
nrestarts = 2;
modelEM = hmmFit(observed, nHidStates, 'discrete', ...
    'convTol', 1e-5, 'nRandomRestarts', nrestarts, 'verbose', true);

%% How different are the respective log probabilities?
fprintf('trueModel LL: %g\n', hmmLogprob(trueModel, observed));
fprintf('emModel LL: %g\n', hmmLogprob(modelEM, observed)); 

%% Decode using true model
decodedFromTrueViterbi = hmmMap(trueModel, observed);
decodedFromTrueViterbi = bestPermutation(decodedFromTrueViterbi, hidden);
trueModelViterbiError = mean(decodedFromTrueViterbi ~= hidden)

decodedFromTrueMaxMarg = maxidx(hmmInferNodes(trueModel, observed), [], 1);
decodedFromTrueMaxMarg = bestPermutation(decodedFromTrueMaxMarg, hidden);
trueModelMaxMargError = mean(decodedFromTrueMaxMarg ~= hidden)

%% Decode using the EM model
decodedFromEMviterbi = hmmMap(modelEM, observed);
decodedFromEMviterbi = bestPermutation(decodedFromEMviterbi, hidden);

emModelViterbiError = mean(decodedFromEMviterbi ~= hidden)

decodedFromEMmaxMarg = maxidx(hmmInferNodes(modelEM, observed), [], 1);
decodedFromEMmaxMarg = bestPermutation(decodedFromEMmaxMarg, hidden);

emModelMaxMargError = mean(decodedFromEMmaxMarg ~= hidden)




##### SOURCE END #####
--></body></html>
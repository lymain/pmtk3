
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML is auto-generated from an M-file.
To make changes, update the M-file and republish this document.
      --><title>Tutorial on  pmtk3</title><meta name="generator" content="MATLAB 7.9"><meta name="date" content="2010-08-26"><meta name="m-file" content="tutFoundations"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h1>Tutorial on  pmtk3</h1><!--introduction--><p><i>This page was auto-generated by publishing</i> <a href="http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/tutFoundations.m">http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/tutFoundations.m</a>.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Overall design of PMTK3</a></li><li><a href="#6">Conditional (supervised) models</a></li><li><a href="#9">Unconditional (unsupervised) models</a></li><li><a href="#12">Basic models</a></li><li><a href="#13">Latent variable models</a></li><li><a href="#16">Graphical models</a></li><li><a href="#19">Summary of models and methods</a></li><li><a href="#22">Passing in optional arguments</a></li><li><a href="#31">Generally useful Matlab functions</a></li></ul></div><h2>Overall design of PMTK3<a name="1"></a></h2><p>PMTK3 has an object oriented design. That is, it can be thought of as defining a series of 'classes', representing different kinds of probabilistic models. Each class  supports various 'methods', which perform certain operations. These methods are often implemented in a functional way.</p><p>We don't actually use Matlab's object oriented system, because this does not work in Octave. In addition, some users find such code harder to understand, and it can be slower than non OO code. Instead, each model 'object' (an instance of a model 'class') is actually just a structure, containing various fields. And each method is just a regular function, whose name begins with the class name. The first argument to a method is a model struct.</p><p>As an example, below we create a 2d Gaussian model and then draw 5 samples from it</p><pre class="codeinput">m = gaussCreate([0 0], eye(2))
X = gaussSample(m, 5)
</pre><pre class="codeoutput">m = 
           mu: [0 0]
        Sigma: [2x2 double]
    modelType: 'gauss'
X =
    0.5377    1.8339
   -2.2588    0.8622
    0.3188   -1.3077
   -0.4336    0.3426
    3.5784    2.7694
</pre><p>The function 'gaussCreate' is called a constructor, since it creates an instance of the class. The function 'gaussSample' is a method. The methods that are supported depend on the type of model; details are given below.</p><p>To provide some overall structure, we group the model classes into two major types:</p><div><ul><li>unconditional / unsupervised</li><li>conditional / supervised</li></ul></div><p>These support different functions, as we explain below.</p><h2>Conditional (supervised) models<a name="6"></a></h2><p>This is a model of the form <img src="tutFoundations_eq31060.png" alt="$p(y|x, \theta)$">, where x is the set of covariats/ inputs, and y is the response. Currently we require y to be a scalar. If <img src="tutFoundations_eq14315.png" alt="$y \in R$">, we are performing regression; if <img src="tutFoundations_eq35391.png" alt="$y \in \{1,\ldots,C\}$">, we are performing classification. We discuss supervised models in more detail <a href="http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tutSupervised.html">here</a>.</p><p>All conditional models should support the functions listed below. In the table,  'foo' is the name of the model class and '...' refers to optional or model-specific arguments (these will be explained later).</p><p>
<TABLE BORDER=3 CELLPADDING=5 WIDTH="100%" >
<TR ALIGN=left>
<TH WIDTH=40%  BGCOLOR=#00CCFF><FONT COLOR=000000>Method</FONT></TH>
<TH WIDTH=60% BGCOLOR=#00CCFF><FONT COLOR=000000>Description</FONT></TH>
</TR>
<tr>
<td> m = fooCreate(...)
<td> Constructor
<tr>
<td> m = fooFit(X, y, ...)
<td> Constructor. Usually computes the MLE
or MAP parameter estimate, using various priors and  fitting algorithms.
X is an N*D design matrix, where
N is the number of training cases, and D is the dimensionality
of the distribution being fit.
y is the N*1 response vector.
<tr>
<td> [yhat, py] = fooPredict(m, X, ...)
<td> The meaning of the outputs depends on the model class.
For classification, yhat(i) = argmax p(y|X(i,:), m),
and py(i,c) = p(y=c|X(i,:), m).
(Note that some models cannot
produce probabilistic outputs. In such cases, py may be
undefined.)
For regression, yhat(i) = E[y|X(i,:),m]
and py(i) = Var[y|X(i,:), m].
<tr>
<td>
<tr>
</table>
</p><p>Most of the work occurs inside the fitting function. See <a href="http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tutSupervised.html">here</a> for details.</p><h2>Unconditional (unsupervised) models<a name="9"></a></h2><p>An unconditional model is of the form <img src="tutFoundations_eq02877.png" alt="$p(y|\theta)$">, where y is potentially vector valued. Such models support the following functions, although in some cases, some functions may not yet have been implemented for a particular model class.</p><p>
<TABLE BORDER=3 CELLPADDING=5 WIDTH="100%" >
<TR ALIGN=left>
<TH WIDTH=40%  BGCOLOR=#00CCFF><FONT COLOR=000000>Method</FONT></TH>
<TH WIDTH=60% BGCOLOR=#00CCFF><FONT COLOR=000000>Description</FONT></TH>
</TR>
<td>  m = fooCreate(...)
<td> Constructor. Allows user to specify the parameters 'by hand',
as well as specifying optional arguments to be used by fitting
and/or inference routines.
<tr>
<td> m = fooFit(X,  ...)
<td> Constructor. Usually computes the MLE
or MAP parameter estimate, using various priors and  fitting algorithms.
X is an N*D design matrix.
For some models, X may contain NaN's, representing missing values.
<tr>
<td>  X = fooSample(m, N)
<td> X(i,:) = sample from model m, i=1:N
<tr>
<td>  L = fooLogprob(m, X)
<td> L(i) = log p(X(i,:)| m)
For some models, X may contain NaN's, representing missing values.
<tr>
</table>
</p><p>Unconditional models are subdivided into various subtypes, as follows:</p><div><ul><li>basic (standard parametric distributions e.g., Gauss)</li><li>latent (mixture models, latent factor models, HMMs etc)</li><li>graphical (models which require specifying a graph structure)</li></ul></div><p>We discuss these  below.</p><h2>Basic models<a name="12"></a></h2><p>Basic models support the functions listed above. Some models (e.g, Gauss) support additional functions. A list of all the basic models can be found <a href="http://pmtk3.googlecode.com/svn/trunk/docs/modelLists/modelList.html">here</a></p><h2>Latent variable models<a name="13"></a></h2><p>We discuss LVMs in more detail <a href="http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tutLVM.html">here</a> Unlike basic distributions, there is a model selection problem of choosing the 'right' number of latent variables. From a functional point of view, an LVM supports all the methods for a generic unconditional model, plus the following functions.</p><p>
<TABLE BORDER=3 CELLPADDING=5 WIDTH="100%" >
<TR ALIGN=left>
<TH WIDTH=40%  BGCOLOR=#00CCFF><FONT COLOR=000000>Method</FONT></TH>
<TH WIDTH=60% BGCOLOR=#00CCFF><FONT COLOR=000000>Description</FONT></TH>
</TR>
<td> [z, pz] = infer(m, X).
<td> This is an unsupervised version of predict.
If the LVM has discrete latent variables z,
z(i) = argmax p(z|X(i,:), m)
and pz(i,k) = p(z=k|X(i,:), m).
If the LVM has continuous latent variables z,
z(i,:) = E(z|X(i,:), m)
and pz(i,:,:) = Cov(z|X(i,:), m).
<tr>
</table>
</p><p>A list of all the LVMs can be found <a href="http://pmtk3.googlecode.com/svn/trunk/docs/modelLists/modelList.html">here</a></p><h2>Graphical models<a name="16"></a></h2><p>We discuss graphical models in more detail <a href="http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tutGM.html">here</a>. Unlike basic distributions, there is a model selection problem of choosing the 'right' graph structure. From a functional point of view, a GM supports all the methods for a generic unconditional model, plus the following functions.</p><p>
<TABLE BORDER=3 CELLPADDING=5 WIDTH="100%" >
<TR ALIGN=left>
<TH WIDTH=40%  BGCOLOR=#00CCFF><FONT COLOR=000000>Method</FONT></TH>
<TH WIDTH=60% BGCOLOR=#00CCFF><FONT COLOR=000000>Description</FONT></TH>
</TR>
<td> [bel] = inferNodes(m, evidence).
<td> Here bel{i}(k) is the probability node i is in state k,
given the evidence. The evidence can be specified
in several different ways. See
<http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tutGM.html
here> for details.
<tr>
<td> yhat = map(m, evidence)
<td> Computes argmax p(y|ev, m), which is a (joint) posterior mode.
<tr>
<td> Ghat = fitStruct(m, evidence)
<td> Find a MAP estimate of the graph structure (not yet implemented).
</table>
</p><p>A list of all the GMs can be found <a href="http://pmtk3.googlecode.com/svn/trunk/docs/modelLists/modelList.html">here</a></p><h2>Summary of models and methods<a name="19"></a></h2><p>A summary of the models and their main methods is shown below</p><p>
<img src="http://pmtk3.googlecode.com/svn/trunk/docs/classSystem/modelsMethodsTree.png">.
</p><h2>Passing in optional arguments<a name="22"></a></h2><p>Many functions take a large number of optional arguments. For example, linregFit (which fit a linear regression model) has the following interface</p><pre>[model] = linregFit(X, y, varargin)</pre><p>varargin represents a variable number of arguments. The optional arguments, and their default values, are printed when you type help('linregFit').</p><pre class="codeinput">help <span class="string">linregFit</span>
</pre><pre class="codeoutput">  Fit a linear regression model by MLE or MAP estimation
  INPUTS
  X             ... N*D design matrix
  y             ... N*1 response vector
  OPTIONAL INPUTS:
  regType       ... L1, L2, none, scad (only used if likelihood is 'gaussian')
  likelihood    ... ['gaussian'], 'student', 'huber'
  lambda        ... regularizer
  fitOptions    ... optional  args (a cell array) to fitFn
  preproc       ... a struct, passed to preprocessorApplyToTtrain
 
  OUTPUTS:
  model         ... a struct, which you can pass directly to linregPredict
 %

</pre><p>The meaning of these arguments will be explained later.</p><p>There are two ways to specify the optional arguments: 1) a set of name, value pairs eg.</p><pre class="codeinput">clear <span class="string">all</span>
N=10; D = 2; X = rand(N, D); y = rand(N,1);
m1 = linregFit(X, y, <span class="string">'regType'</span>, <span class="string">'L2'</span>, <span class="string">'lambda'</span>, 2)
</pre><pre class="codeoutput">m1 = 
        lambda: 2
             w: [3x1 double]
        sigma2: 0.0093
       preproc: [1x1 struct]
     modelType: 'linreg'
    likelihood: 'gaussian'
</pre><p>2) a struct, where the fields are named after the optional arguments, eg.</p><pre class="codeinput">s.regType = <span class="string">'L2'</span>;
s.lambda = 2;
m2 = linregFit(X, y, s)
</pre><pre class="codeoutput">m2 = 
        lambda: 2
             w: [3x1 double]
        sigma2: 0.0093
       preproc: [1x1 struct]
     modelType: 'linreg'
    likelihood: 'gaussian'
</pre><p>As a sanity check, let us check these are equal</p><pre class="codeinput">assert(approxeq(m1.w, m2.w))
</pre><p>Internally, these optional arguments are processed using <a href="http://matlabtools.googlecode.com/svn/trunk/util/process_options.m">process_options.m</a>, written by Mark Paskin, and <a href="http://matlabtools.googlecode.com/svn/trunk/util/prepareArgs.m">prepareArgs.m</a>, written by Matt Dunham. For more detals, see <a href="http://yagtom.googlecode.com/svn/trunk/html/writingFunctions.html#40">this entry</a> in our Matlab tutorial.</p><h2>Generally useful Matlab functions<a name="31"></a></h2><p>PMTK uses a large number of  functions that are useful for many different purposes outside of machine learning. Many of these are stored in our <a href="http://code.google.com/p/matlabtools/">matlabTools</a> site. Others are built-in to Matlab, as explained in our <a href="http://code.google.com/p/yagtom/">Matlab tutorial</a>. We mention just a few of the most useful ones below</p><div><ul><li>whoCallsMe('foo'): list all files that call foo.m</li><li>which('foo'): print directory where foo.m/ foo.mex is stored.     This will help you determine if the function is builtin, part of     PMTK, part of some other toolbox, etc.</li><li>help('foo'): prints any initial documentation for foo.m that     the implementer may have provided; all builtin Matlab functions     are properly documented. Unfortuntately that is not the case for     all the PMTK functions... but you can always read the source.     (Since pmtk is open source, we open members of the community      will help improve the quality of the code and the documentation      over time.)</li><li>edit('foo'): open foo.m in editor, lets you look at source code   (be careful not to change things accidently!). This also works   for built-in Matlab functions.</li></ul></div><p class="footer"><br>
      Published with MATLAB&reg; 7.9<br></p></div><!--
##### SOURCE BEGIN #####
%% Tutorial on  pmtk3
% _This page was auto-generated by publishing_
% <http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/tutFoundations.m>.


%% Overall design of PMTK3
% PMTK3 has an object oriented design.
% That is, it can be thought of as defining a series of 'classes',
% representing different kinds of probabilistic models.
% Each class  supports
% various 'methods', which perform certain operations.
% These methods are often implemented in a functional way.
%
% We don't actually use Matlab's object oriented system,
% because this does not work in Octave.
% In addition, some users find such code harder to understand,
% and it can be slower than non OO code.
% Instead, each model 'object' (an instance of a model 'class')
% is actually just a structure, containing various fields.
% And each method is just a regular function, whose name begins
% with the class name. The first argument to a method 
% is a model struct. 
%
% As an example, below we create a 2d Gaussian model
% and then draw 5 samples from it
%%
m = gaussCreate([0 0], eye(2))
X = gaussSample(m, 5)
%%
% The function 'gaussCreate' is called a constructor,
% since it creates an instance of the class.
% The function 'gaussSample' is a method.
% The methods that are supported depend on the type of model;
% details are given below.
%
% To provide some overall structure, we group the model
% classes into two major types:
%%
% * unconditional / unsupervised
% * conditional / supervised
%%
% These support different functions, as we explain below.

%% Conditional (supervised) models 
% This is a model of the form $p(y|x, \theta)$,
% where x is the set of covariats/ inputs,
% and y is the response. Currently we require y to be a scalar.
% If $y \in R$, we are performing regression;
% if $y \in \{1,\ldots,C\}$, we are performing classification.
% We discuss supervised models in more detail 
% <http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tutSupervised.html here>.
%
% All conditional models should support the functions listed below.
% In the table,  'foo' is the name of the model class
% and '...' refers to optional or model-specific arguments
% (these will be explained later).
%%
% <html>
% <TABLE BORDER=3 CELLPADDING=5 WIDTH="100%" >
% <TR ALIGN=left>
% <TH WIDTH=40%  BGCOLOR=#00CCFF><FONT COLOR=000000>Method</FONT></TH>
% <TH WIDTH=60% BGCOLOR=#00CCFF><FONT COLOR=000000>Description</FONT></TH>
% </TR>
% <tr>
% <td> m = fooCreate(...)
% <td> Constructor
% <tr>
% <td> m = fooFit(X, y, ...)
% <td> Constructor. Usually computes the MLE
% or MAP parameter estimate, using various priors and  fitting algorithms.
% X is an N*D design matrix, where
% N is the number of training cases, and D is the dimensionality
% of the distribution being fit. 
% y is the N*1 response vector.
% <tr>
% <td> [yhat, py] = fooPredict(m, X, ...)
% <td> The meaning of the outputs depends on the model class.
% For classification, yhat(i) = argmax p(y|X(i,:), m),
% and py(i,c) = p(y=c|X(i,:), m). 
% (Note that some models cannot
% produce probabilistic outputs. In such cases, py may be
% undefined.)
% For regression, yhat(i) = E[y|X(i,:),m]
% and py(i) = Var[y|X(i,:), m]. 
% <tr>
% <td>
% <tr>
% </table>
% </html>
%%
% Most of the work occurs inside the fitting function.
% See 
% <http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tutSupervised.html here>
% for details.

%% Unconditional (unsupervised) models
% An unconditional model is of the form $p(y|\theta)$,
% where y is potentially vector valued.
% Such models support the following functions,
% although in some cases, some functions may not
% yet have been implemented for a particular model class.
%%
% <html>
% <TABLE BORDER=3 CELLPADDING=5 WIDTH="100%" >
% <TR ALIGN=left>
% <TH WIDTH=40%  BGCOLOR=#00CCFF><FONT COLOR=000000>Method</FONT></TH>
% <TH WIDTH=60% BGCOLOR=#00CCFF><FONT COLOR=000000>Description</FONT></TH>
% </TR>
% <td>  m = fooCreate(...)
% <td> Constructor. Allows user to specify the parameters 'by hand',
% as well as specifying optional arguments to be used by fitting
% and/or inference routines.
% <tr>
% <td> m = fooFit(X,  ...)
% <td> Constructor. Usually computes the MLE
% or MAP parameter estimate, using various priors and  fitting algorithms.
% X is an N*D design matrix.
% For some models, X may contain NaN's, representing missing values.
% <tr>
% <td>  X = fooSample(m, N)
% <td> X(i,:) = sample from model m, i=1:N
% <tr>
% <td>  L = fooLogprob(m, X)
% <td> L(i) = log p(X(i,:)| m) 
% For some models, X may contain NaN's, representing missing values.
% <tr>
% </table>
% </html>
%%
% Unconditional models are subdivided
% into various subtypes, as follows:
%
% * basic (standard parametric distributions e.g., Gauss)
% * latent (mixture models, latent factor models, HMMs etc)
% * graphical (models which require specifying a graph structure)
%
% We discuss these  below.

%% Basic models
% Basic models support the functions listed above.
% Some models (e.g, Gauss) support additional functions.
% A list of all the basic models can be found
% <http://pmtk3.googlecode.com/svn/trunk/docs/modelLists/modelList.html
% here>

%% Latent variable models
% We discuss LVMs in more detail 
% <http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tutLVM.html
% here>
% Unlike basic distributions, there is a model selection
% problem of choosing the 'right' number of latent variables.
% From a functional point of view, an LVM supports
% all the methods for a generic unconditional model,
% plus the following functions.
%%
% <html>
% <TABLE BORDER=3 CELLPADDING=5 WIDTH="100%" >
% <TR ALIGN=left>
% <TH WIDTH=40%  BGCOLOR=#00CCFF><FONT COLOR=000000>Method</FONT></TH>
% <TH WIDTH=60% BGCOLOR=#00CCFF><FONT COLOR=000000>Description</FONT></TH>
% </TR>
% <td> [z, pz] = infer(m, X).
% <td> This is an unsupervised version of predict.
% If the LVM has discrete latent variables z,
% z(i) = argmax p(z|X(i,:), m)
% and pz(i,k) = p(z=k|X(i,:), m).
% If the LVM has continuous latent variables z,
% z(i,:) = E(z|X(i,:), m)
% and pz(i,:,:) = Cov(z|X(i,:), m).
% <tr>
% </table>
% </html>
%%
% A list of all the LVMs can be found
% <http://pmtk3.googlecode.com/svn/trunk/docs/modelLists/modelList.html
% here>

%% Graphical models
% We discuss graphical models in more detail
% <http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tutGM.html
% here>.
% Unlike basic distributions, there is a model selection
% problem of choosing the 'right' graph structure.
% From a functional point of view, a GM supports
% all the methods for a generic unconditional model,
% plus the following functions.
%%
% <html>
% <TABLE BORDER=3 CELLPADDING=5 WIDTH="100%" >
% <TR ALIGN=left>
% <TH WIDTH=40%  BGCOLOR=#00CCFF><FONT COLOR=000000>Method</FONT></TH>
% <TH WIDTH=60% BGCOLOR=#00CCFF><FONT COLOR=000000>Description</FONT></TH>
% </TR>
% <td> [bel] = inferNodes(m, evidence).
% <td> Here bel{i}(k) is the probability node i is in state k,
% given the evidence. The evidence can be specified
% in several different ways. See 
% <http://pmtk3.googlecode.com/svn/trunk/docs/tutorial/html/tutGM.html
% here> for details.
% <tr> 
% <td> yhat = map(m, evidence)
% <td> Computes argmax p(y|ev, m), which is a (joint) posterior mode.
% <tr> 
% <td> Ghat = fitStruct(m, evidence)
% <td> Find a MAP estimate of the graph structure (not yet implemented).
% </table>
% </html>
%%
% A list of all the GMs can be found
% <http://pmtk3.googlecode.com/svn/trunk/docs/modelLists/modelList.html
% here>
%% Summary of models and methods
% 
% A summary of the models and their main methods is shown below
%%
% <html>
% <img src="http://pmtk3.googlecode.com/svn/trunk/docs/classSystem/modelsMethodsTree.png">.
% </html>
%%

%% Passing in optional arguments
% Many functions take a large number of optional arguments.
% For example, linregFit (which fit a linear regression model)
% has the following interface
%
%  [model] = linregFit(X, y, varargin)
%
% varargin represents a variable number of arguments.
% The optional arguments, and their default values, are printed
% when you type help('linregFit').
%%
help linregFit
%%
% The meaning of these arguments will be explained
% later.
%
% There are two ways to specify the optional arguments:
% 1) a set of name, value pairs eg.
%%
clear all
N=10; D = 2; X = rand(N, D); y = rand(N,1);
m1 = linregFit(X, y, 'regType', 'L2', 'lambda', 2)
%%
% 2) a struct, where the fields are named after the optional
% arguments, eg.
%%
s.regType = 'L2'; 
s.lambda = 2;
m2 = linregFit(X, y, s)
%%
% As a sanity check, let us check these are equal
%%
assert(approxeq(m1.w, m2.w))
%%
% Internally, these optional arguments are processed using
% <http://matlabtools.googlecode.com/svn/trunk/util/process_options.m
% process_options.m>, written by Mark Paskin, and
% <http://matlabtools.googlecode.com/svn/trunk/util/prepareArgs.m
% prepareArgs.m>, written by Matt Dunham.
% For more detals, see
% <http://yagtom.googlecode.com/svn/trunk/html/writingFunctions.html#40
% this entry> in our Matlab tutorial.


%% Generally useful Matlab functions
% PMTK uses a large number of  functions
% that are useful for many different purposes outside of
% machine learning. Many of these are stored
% in our <http://code.google.com/p/matlabtools/ matlabTools> site.
% Others are built-in to Matlab, as explained
% in our <http://code.google.com/p/yagtom/ Matlab tutorial>.
% We mention just a few of the most useful ones below
%
% * whoCallsMe('foo'): list all files that call foo.m
% * which('foo'): print directory where foo.m/ foo.mex is stored.
%     This will help you determine if the function is builtin, part of
%     PMTK, part of some other toolbox, etc.
% * help('foo'): prints any initial documentation for foo.m that
%     the implementer may have provided; all builtin Matlab functions
%     are properly documented. Unfortuntately that is not the case for
%     all the PMTK functions... but you can always read the source.
%     (Since pmtk is open source, we open members of the community
%      will help improve the quality of the code and the documentation
%      over time.)
% * edit('foo'): open foo.m in editor, lets you look at source code
%   (be careful not to change things accidently!). This also works
%   for built-in Matlab functions. 
%

##### SOURCE END #####
--></body></html>
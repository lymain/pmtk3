%% Supervised learning using sparse parametric discriminative models in pmtk3
% _This page was auto-generated by publishing_
% tutSparseClassif.m
%
% There has been a lot of recent interest in models which only
% use a subset of the features/ variables. These are known as 
% sparse models. pmtk supports several ways of promoting sparsity,
% and selecting relevant variables, some of which we discuss below.
%
%% L1 regularization 
% The best known way to encourage sparsity
% is to use L1 regularization.
% This is equivalent to MAP estimation under a Laplace prior.
% When combined with linear or logistic regression,
% the overall objective is convex.
% However, 
% finding the MAP estimate  is a bit tricky because the prior
% is not differentiable at the origin,  hence the objective,
% while convex, is not smooth.
%
% There are many different optimization algorithms one can use; this is currently
% a hot topic of research.
% In pmtk, we use Mark Schmidt's
% <http://www.cs.ubc.ca/~schmidtm/Software/L1General/L1General.html
% L1general> package.
% (A version is included in
% <http://code.google.com/p/pmtksupport/ pmtkSupport>.)
% This can be used for a variety of different models.

